{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. 로지스틱 회귀.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNDj48bCxUwludp+QkNIpuK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hotdog1029/deeplearning/blob/main/3_%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IIQSJ6d7adt"
      },
      "source": [
        "로지스틱 회귀: 이진분류를 풀기위한 대표적인 알고리즘 , 그럼 회귀가 아니라 분류아님??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHKxU3KO7cpL"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8C0N6wq7Mji",
        "outputId": "318fa837-1c14-4629-923d-83e35e48511f"
      },
      "source": [
        "# 데이터 선언\r\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\r\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\r\n",
        "x_train = torch.FloatTensor(x_data)\r\n",
        "y_train = torch.FloatTensor(y_data)\r\n",
        "\r\n",
        "# 모델 초기화\r\n",
        "W = torch.zeros((2, 1), requires_grad=True) # x_train이 6 x 2의 크기를 가지는 행렬이니까 XW가 성립되기 위해서는 W의 크기는 2 X 1이여야 한다.\r\n",
        "b = torch.zeros(1, requires_grad=True)\r\n",
        "\r\n",
        "# optimizer 설정\r\n",
        "optimizer = optim.SGD([W,b], lr = 1)\r\n",
        "\r\n",
        "nb_epochs = 1000\r\n",
        "for epoch in range(nb_epochs + 1):\r\n",
        "  # 가설 설정\r\n",
        "  # hypothesis = 1/ (1 +torch.exp(-(x_train.matmul))) 이 식을 더 쉽게 만드는 것이 sigmoid 함수(matmul함수는 행렬의 곱을 값을 출력하는 함수)\r\n",
        "  hypothesis = torch.sigmoid(x_train.matmul(W) + b)\r\n",
        "  \r\n",
        "  # cost 계산\r\n",
        "  cost = -(y_train * torch.log(hypothesis) + (1 - y_train) * torch.log(1 - hypothesis)).mean()\r\n",
        "\r\n",
        "  # cost로 H(x) 개선\r\n",
        "  optimizer.zero_grad()\r\n",
        "  cost.backward()\r\n",
        "  optimizer.step()\r\n",
        "  # 100번마다 로그 출력\r\n",
        "  if epoch % 100 == 0:\r\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\r\n",
        "          epoch, nb_epochs, cost.item()\r\n",
        "      ))\r\n",
        "print(hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 Cost: 0.693147\n",
            "Epoch  100/1000 Cost: 0.134722\n",
            "Epoch  200/1000 Cost: 0.080643\n",
            "Epoch  300/1000 Cost: 0.057900\n",
            "Epoch  400/1000 Cost: 0.045300\n",
            "Epoch  500/1000 Cost: 0.037261\n",
            "Epoch  600/1000 Cost: 0.031673\n",
            "Epoch  700/1000 Cost: 0.027556\n",
            "Epoch  800/1000 Cost: 0.024394\n",
            "Epoch  900/1000 Cost: 0.021888\n",
            "Epoch 1000/1000 Cost: 0.019852\n",
            "tensor([[2.7711e-04],\n",
            "        [3.1636e-02],\n",
            "        [3.9014e-02],\n",
            "        [9.5618e-01],\n",
            "        [9.9823e-01],\n",
            "        [9.9969e-01]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg8GnWh5-ILl",
        "outputId": "1ce76b9a-f455-4172-936e-8586de16f28b"
      },
      "source": [
        "# nn.Module로 구현하는 로지스틱 회귀\r\n",
        "\r\n",
        "# 데이터 설정\r\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\r\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\r\n",
        "x_train = torch.FloatTensor(x_data)\r\n",
        "y_train = torch.FloatTensor(y_data)\r\n",
        "\r\n",
        "model = nn.Sequential(\r\n",
        "   nn.Linear(2, 1), # input_dim = 2, output_dim = 1\r\n",
        "   nn.Sigmoid() # 출력은 시그모이드 함수를 거친다\r\n",
        ")\r\n",
        "\r\n",
        "# optimizer 설정\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\r\n",
        "\r\n",
        "nb_epochs = 1000\r\n",
        "for epoch in range(nb_epochs + 1):\r\n",
        "\r\n",
        "    # H(x) 계산\r\n",
        "    hypothesis = model(x_train)\r\n",
        "\r\n",
        "    # cost 계산\r\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\r\n",
        "\r\n",
        "    # cost로 H(x) 개선\r\n",
        "    optimizer.zero_grad()\r\n",
        "    cost.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # 20번마다 로그 출력\r\n",
        "    if epoch % 10 == 0:\r\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\r\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\r\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\r\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\r\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\r\n",
        "        ))\r\n",
        "\r\n",
        "print(list(model.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 Cost: 1.277477 Accuracy 16.67%\n",
            "Epoch   10/1000 Cost: 0.584874 Accuracy 66.67%\n",
            "Epoch   20/1000 Cost: 0.542427 Accuracy 83.33%\n",
            "Epoch   30/1000 Cost: 0.435880 Accuracy 83.33%\n",
            "Epoch   40/1000 Cost: 0.351741 Accuracy 83.33%\n",
            "Epoch   50/1000 Cost: 0.274028 Accuracy 83.33%\n",
            "Epoch   60/1000 Cost: 0.209046 Accuracy 83.33%\n",
            "Epoch   70/1000 Cost: 0.167825 Accuracy 100.00%\n",
            "Epoch   80/1000 Cost: 0.149294 Accuracy 100.00%\n",
            "Epoch   90/1000 Cost: 0.138508 Accuracy 100.00%\n",
            "Epoch  100/1000 Cost: 0.129464 Accuracy 100.00%\n",
            "Epoch  110/1000 Cost: 0.121552 Accuracy 100.00%\n",
            "Epoch  120/1000 Cost: 0.114569 Accuracy 100.00%\n",
            "Epoch  130/1000 Cost: 0.108360 Accuracy 100.00%\n",
            "Epoch  140/1000 Cost: 0.102803 Accuracy 100.00%\n",
            "Epoch  150/1000 Cost: 0.097800 Accuracy 100.00%\n",
            "Epoch  160/1000 Cost: 0.093273 Accuracy 100.00%\n",
            "Epoch  170/1000 Cost: 0.089157 Accuracy 100.00%\n",
            "Epoch  180/1000 Cost: 0.085397 Accuracy 100.00%\n",
            "Epoch  190/1000 Cost: 0.081949 Accuracy 100.00%\n",
            "Epoch  200/1000 Cost: 0.078776 Accuracy 100.00%\n",
            "Epoch  210/1000 Cost: 0.075845 Accuracy 100.00%\n",
            "Epoch  220/1000 Cost: 0.073130 Accuracy 100.00%\n",
            "Epoch  230/1000 Cost: 0.070607 Accuracy 100.00%\n",
            "Epoch  240/1000 Cost: 0.068257 Accuracy 100.00%\n",
            "Epoch  250/1000 Cost: 0.066061 Accuracy 100.00%\n",
            "Epoch  260/1000 Cost: 0.064006 Accuracy 100.00%\n",
            "Epoch  270/1000 Cost: 0.062078 Accuracy 100.00%\n",
            "Epoch  280/1000 Cost: 0.060266 Accuracy 100.00%\n",
            "Epoch  290/1000 Cost: 0.058558 Accuracy 100.00%\n",
            "Epoch  300/1000 Cost: 0.056947 Accuracy 100.00%\n",
            "Epoch  310/1000 Cost: 0.055424 Accuracy 100.00%\n",
            "Epoch  320/1000 Cost: 0.053983 Accuracy 100.00%\n",
            "Epoch  330/1000 Cost: 0.052616 Accuracy 100.00%\n",
            "Epoch  340/1000 Cost: 0.051317 Accuracy 100.00%\n",
            "Epoch  350/1000 Cost: 0.050083 Accuracy 100.00%\n",
            "Epoch  360/1000 Cost: 0.048908 Accuracy 100.00%\n",
            "Epoch  370/1000 Cost: 0.047788 Accuracy 100.00%\n",
            "Epoch  380/1000 Cost: 0.046719 Accuracy 100.00%\n",
            "Epoch  390/1000 Cost: 0.045697 Accuracy 100.00%\n",
            "Epoch  400/1000 Cost: 0.044721 Accuracy 100.00%\n",
            "Epoch  410/1000 Cost: 0.043785 Accuracy 100.00%\n",
            "Epoch  420/1000 Cost: 0.042889 Accuracy 100.00%\n",
            "Epoch  430/1000 Cost: 0.042030 Accuracy 100.00%\n",
            "Epoch  440/1000 Cost: 0.041204 Accuracy 100.00%\n",
            "Epoch  450/1000 Cost: 0.040412 Accuracy 100.00%\n",
            "Epoch  460/1000 Cost: 0.039649 Accuracy 100.00%\n",
            "Epoch  470/1000 Cost: 0.038915 Accuracy 100.00%\n",
            "Epoch  480/1000 Cost: 0.038209 Accuracy 100.00%\n",
            "Epoch  490/1000 Cost: 0.037528 Accuracy 100.00%\n",
            "Epoch  500/1000 Cost: 0.036871 Accuracy 100.00%\n",
            "Epoch  510/1000 Cost: 0.036237 Accuracy 100.00%\n",
            "Epoch  520/1000 Cost: 0.035625 Accuracy 100.00%\n",
            "Epoch  530/1000 Cost: 0.035033 Accuracy 100.00%\n",
            "Epoch  540/1000 Cost: 0.034461 Accuracy 100.00%\n",
            "Epoch  550/1000 Cost: 0.033908 Accuracy 100.00%\n",
            "Epoch  560/1000 Cost: 0.033373 Accuracy 100.00%\n",
            "Epoch  570/1000 Cost: 0.032854 Accuracy 100.00%\n",
            "Epoch  580/1000 Cost: 0.032351 Accuracy 100.00%\n",
            "Epoch  590/1000 Cost: 0.031864 Accuracy 100.00%\n",
            "Epoch  600/1000 Cost: 0.031391 Accuracy 100.00%\n",
            "Epoch  610/1000 Cost: 0.030933 Accuracy 100.00%\n",
            "Epoch  620/1000 Cost: 0.030488 Accuracy 100.00%\n",
            "Epoch  630/1000 Cost: 0.030055 Accuracy 100.00%\n",
            "Epoch  640/1000 Cost: 0.029635 Accuracy 100.00%\n",
            "Epoch  650/1000 Cost: 0.029226 Accuracy 100.00%\n",
            "Epoch  660/1000 Cost: 0.028829 Accuracy 100.00%\n",
            "Epoch  670/1000 Cost: 0.028443 Accuracy 100.00%\n",
            "Epoch  680/1000 Cost: 0.028067 Accuracy 100.00%\n",
            "Epoch  690/1000 Cost: 0.027700 Accuracy 100.00%\n",
            "Epoch  700/1000 Cost: 0.027344 Accuracy 100.00%\n",
            "Epoch  710/1000 Cost: 0.026996 Accuracy 100.00%\n",
            "Epoch  720/1000 Cost: 0.026657 Accuracy 100.00%\n",
            "Epoch  730/1000 Cost: 0.026327 Accuracy 100.00%\n",
            "Epoch  740/1000 Cost: 0.026005 Accuracy 100.00%\n",
            "Epoch  750/1000 Cost: 0.025691 Accuracy 100.00%\n",
            "Epoch  760/1000 Cost: 0.025384 Accuracy 100.00%\n",
            "Epoch  770/1000 Cost: 0.025085 Accuracy 100.00%\n",
            "Epoch  780/1000 Cost: 0.024793 Accuracy 100.00%\n",
            "Epoch  790/1000 Cost: 0.024507 Accuracy 100.00%\n",
            "Epoch  800/1000 Cost: 0.024228 Accuracy 100.00%\n",
            "Epoch  810/1000 Cost: 0.023956 Accuracy 100.00%\n",
            "Epoch  820/1000 Cost: 0.023689 Accuracy 100.00%\n",
            "Epoch  830/1000 Cost: 0.023429 Accuracy 100.00%\n",
            "Epoch  840/1000 Cost: 0.023174 Accuracy 100.00%\n",
            "Epoch  850/1000 Cost: 0.022924 Accuracy 100.00%\n",
            "Epoch  860/1000 Cost: 0.022680 Accuracy 100.00%\n",
            "Epoch  870/1000 Cost: 0.022442 Accuracy 100.00%\n",
            "Epoch  880/1000 Cost: 0.022208 Accuracy 100.00%\n",
            "Epoch  890/1000 Cost: 0.021979 Accuracy 100.00%\n",
            "Epoch  900/1000 Cost: 0.021755 Accuracy 100.00%\n",
            "Epoch  910/1000 Cost: 0.021535 Accuracy 100.00%\n",
            "Epoch  920/1000 Cost: 0.021320 Accuracy 100.00%\n",
            "Epoch  930/1000 Cost: 0.021109 Accuracy 100.00%\n",
            "Epoch  940/1000 Cost: 0.020902 Accuracy 100.00%\n",
            "Epoch  950/1000 Cost: 0.020699 Accuracy 100.00%\n",
            "Epoch  960/1000 Cost: 0.020501 Accuracy 100.00%\n",
            "Epoch  970/1000 Cost: 0.020306 Accuracy 100.00%\n",
            "Epoch  980/1000 Cost: 0.020114 Accuracy 100.00%\n",
            "Epoch  990/1000 Cost: 0.019927 Accuracy 100.00%\n",
            "Epoch 1000/1000 Cost: 0.019742 Accuracy 100.00%\n",
            "[Parameter containing:\n",
            "tensor([[3.2584, 1.5208]], requires_grad=True), Parameter containing:\n",
            "tensor([-14.5068], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omn4hTC6-IPD",
        "outputId": "1c8d795a-179b-490f-dece-babaf60d6d1f"
      },
      "source": [
        "# 로지스틱 회귀 클래스로 구현\r\n",
        "\r\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\r\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\r\n",
        "x_train = torch.FloatTensor(x_data)\r\n",
        "y_train = torch.FloatTensor(y_data)\r\n",
        "\r\n",
        "class BinaryClassifier(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.linear = nn.Linear(2, 1)\r\n",
        "        self.sigmoid = nn.Sigmoid()\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        return self.sigmoid(self.linear(x))\r\n",
        "\r\n",
        "model = BinaryClassifier()\r\n",
        "\r\n",
        "# optimizer 설정\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\r\n",
        "\r\n",
        "nb_epochs = 1000\r\n",
        "for epoch in range(nb_epochs + 1):\r\n",
        "\r\n",
        "    # H(x) 계산\r\n",
        "    hypothesis = model(x_train)\r\n",
        "\r\n",
        "    # cost 계산\r\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\r\n",
        "\r\n",
        "    # cost로 H(x) 개선\r\n",
        "    optimizer.zero_grad()\r\n",
        "    cost.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # 20번마다 로그 출력\r\n",
        "    if epoch % 10 == 0:\r\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\r\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\r\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\r\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\r\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\r\n",
        "        ))\r\n",
        "print(list(model.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 Cost: 1.961631 Accuracy 50.00%\n",
            "Epoch   10/1000 Cost: 0.839289 Accuracy 66.67%\n",
            "Epoch   20/1000 Cost: 0.561003 Accuracy 83.33%\n",
            "Epoch   30/1000 Cost: 0.462067 Accuracy 83.33%\n",
            "Epoch   40/1000 Cost: 0.377142 Accuracy 83.33%\n",
            "Epoch   50/1000 Cost: 0.297250 Accuracy 83.33%\n",
            "Epoch   60/1000 Cost: 0.227173 Accuracy 83.33%\n",
            "Epoch   70/1000 Cost: 0.177677 Accuracy 100.00%\n",
            "Epoch   80/1000 Cost: 0.153573 Accuracy 100.00%\n",
            "Epoch   90/1000 Cost: 0.141598 Accuracy 100.00%\n",
            "Epoch  100/1000 Cost: 0.132140 Accuracy 100.00%\n",
            "Epoch  110/1000 Cost: 0.123901 Accuracy 100.00%\n",
            "Epoch  120/1000 Cost: 0.116648 Accuracy 100.00%\n",
            "Epoch  130/1000 Cost: 0.110213 Accuracy 100.00%\n",
            "Epoch  140/1000 Cost: 0.104465 Accuracy 100.00%\n",
            "Epoch  150/1000 Cost: 0.099300 Accuracy 100.00%\n",
            "Epoch  160/1000 Cost: 0.094633 Accuracy 100.00%\n",
            "Epoch  170/1000 Cost: 0.090395 Accuracy 100.00%\n",
            "Epoch  180/1000 Cost: 0.086529 Accuracy 100.00%\n",
            "Epoch  190/1000 Cost: 0.082989 Accuracy 100.00%\n",
            "Epoch  200/1000 Cost: 0.079734 Accuracy 100.00%\n",
            "Epoch  210/1000 Cost: 0.076731 Accuracy 100.00%\n",
            "Epoch  220/1000 Cost: 0.073951 Accuracy 100.00%\n",
            "Epoch  230/1000 Cost: 0.071371 Accuracy 100.00%\n",
            "Epoch  240/1000 Cost: 0.068969 Accuracy 100.00%\n",
            "Epoch  250/1000 Cost: 0.066727 Accuracy 100.00%\n",
            "Epoch  260/1000 Cost: 0.064630 Accuracy 100.00%\n",
            "Epoch  270/1000 Cost: 0.062664 Accuracy 100.00%\n",
            "Epoch  280/1000 Cost: 0.060817 Accuracy 100.00%\n",
            "Epoch  290/1000 Cost: 0.059078 Accuracy 100.00%\n",
            "Epoch  300/1000 Cost: 0.057438 Accuracy 100.00%\n",
            "Epoch  310/1000 Cost: 0.055888 Accuracy 100.00%\n",
            "Epoch  320/1000 Cost: 0.054422 Accuracy 100.00%\n",
            "Epoch  330/1000 Cost: 0.053032 Accuracy 100.00%\n",
            "Epoch  340/1000 Cost: 0.051713 Accuracy 100.00%\n",
            "Epoch  350/1000 Cost: 0.050460 Accuracy 100.00%\n",
            "Epoch  360/1000 Cost: 0.049267 Accuracy 100.00%\n",
            "Epoch  370/1000 Cost: 0.048130 Accuracy 100.00%\n",
            "Epoch  380/1000 Cost: 0.047045 Accuracy 100.00%\n",
            "Epoch  390/1000 Cost: 0.046010 Accuracy 100.00%\n",
            "Epoch  400/1000 Cost: 0.045019 Accuracy 100.00%\n",
            "Epoch  410/1000 Cost: 0.044071 Accuracy 100.00%\n",
            "Epoch  420/1000 Cost: 0.043163 Accuracy 100.00%\n",
            "Epoch  430/1000 Cost: 0.042293 Accuracy 100.00%\n",
            "Epoch  440/1000 Cost: 0.041457 Accuracy 100.00%\n",
            "Epoch  450/1000 Cost: 0.040654 Accuracy 100.00%\n",
            "Epoch  460/1000 Cost: 0.039883 Accuracy 100.00%\n",
            "Epoch  470/1000 Cost: 0.039140 Accuracy 100.00%\n",
            "Epoch  480/1000 Cost: 0.038425 Accuracy 100.00%\n",
            "Epoch  490/1000 Cost: 0.037736 Accuracy 100.00%\n",
            "Epoch  500/1000 Cost: 0.037072 Accuracy 100.00%\n",
            "Epoch  510/1000 Cost: 0.036431 Accuracy 100.00%\n",
            "Epoch  520/1000 Cost: 0.035813 Accuracy 100.00%\n",
            "Epoch  530/1000 Cost: 0.035215 Accuracy 100.00%\n",
            "Epoch  540/1000 Cost: 0.034637 Accuracy 100.00%\n",
            "Epoch  550/1000 Cost: 0.034078 Accuracy 100.00%\n",
            "Epoch  560/1000 Cost: 0.033537 Accuracy 100.00%\n",
            "Epoch  570/1000 Cost: 0.033013 Accuracy 100.00%\n",
            "Epoch  580/1000 Cost: 0.032506 Accuracy 100.00%\n",
            "Epoch  590/1000 Cost: 0.032014 Accuracy 100.00%\n",
            "Epoch  600/1000 Cost: 0.031537 Accuracy 100.00%\n",
            "Epoch  610/1000 Cost: 0.031074 Accuracy 100.00%\n",
            "Epoch  620/1000 Cost: 0.030625 Accuracy 100.00%\n",
            "Epoch  630/1000 Cost: 0.030188 Accuracy 100.00%\n",
            "Epoch  640/1000 Cost: 0.029764 Accuracy 100.00%\n",
            "Epoch  650/1000 Cost: 0.029352 Accuracy 100.00%\n",
            "Epoch  660/1000 Cost: 0.028951 Accuracy 100.00%\n",
            "Epoch  670/1000 Cost: 0.028562 Accuracy 100.00%\n",
            "Epoch  680/1000 Cost: 0.028182 Accuracy 100.00%\n",
            "Epoch  690/1000 Cost: 0.027813 Accuracy 100.00%\n",
            "Epoch  700/1000 Cost: 0.027453 Accuracy 100.00%\n",
            "Epoch  710/1000 Cost: 0.027103 Accuracy 100.00%\n",
            "Epoch  720/1000 Cost: 0.026762 Accuracy 100.00%\n",
            "Epoch  730/1000 Cost: 0.026429 Accuracy 100.00%\n",
            "Epoch  740/1000 Cost: 0.026104 Accuracy 100.00%\n",
            "Epoch  750/1000 Cost: 0.025788 Accuracy 100.00%\n",
            "Epoch  760/1000 Cost: 0.025479 Accuracy 100.00%\n",
            "Epoch  770/1000 Cost: 0.025177 Accuracy 100.00%\n",
            "Epoch  780/1000 Cost: 0.024883 Accuracy 100.00%\n",
            "Epoch  790/1000 Cost: 0.024595 Accuracy 100.00%\n",
            "Epoch  800/1000 Cost: 0.024314 Accuracy 100.00%\n",
            "Epoch  810/1000 Cost: 0.024040 Accuracy 100.00%\n",
            "Epoch  820/1000 Cost: 0.023771 Accuracy 100.00%\n",
            "Epoch  830/1000 Cost: 0.023509 Accuracy 100.00%\n",
            "Epoch  840/1000 Cost: 0.023252 Accuracy 100.00%\n",
            "Epoch  850/1000 Cost: 0.023001 Accuracy 100.00%\n",
            "Epoch  860/1000 Cost: 0.022756 Accuracy 100.00%\n",
            "Epoch  870/1000 Cost: 0.022515 Accuracy 100.00%\n",
            "Epoch  880/1000 Cost: 0.022280 Accuracy 100.00%\n",
            "Epoch  890/1000 Cost: 0.022050 Accuracy 100.00%\n",
            "Epoch  900/1000 Cost: 0.021824 Accuracy 100.00%\n",
            "Epoch  910/1000 Cost: 0.021603 Accuracy 100.00%\n",
            "Epoch  920/1000 Cost: 0.021386 Accuracy 100.00%\n",
            "Epoch  930/1000 Cost: 0.021174 Accuracy 100.00%\n",
            "Epoch  940/1000 Cost: 0.020966 Accuracy 100.00%\n",
            "Epoch  950/1000 Cost: 0.020762 Accuracy 100.00%\n",
            "Epoch  960/1000 Cost: 0.020562 Accuracy 100.00%\n",
            "Epoch  970/1000 Cost: 0.020366 Accuracy 100.00%\n",
            "Epoch  980/1000 Cost: 0.020173 Accuracy 100.00%\n",
            "Epoch  990/1000 Cost: 0.019984 Accuracy 100.00%\n",
            "Epoch 1000/1000 Cost: 0.019799 Accuracy 100.00%\n",
            "[Parameter containing:\n",
            "tensor([[3.2556, 1.5193]], requires_grad=True), Parameter containing:\n",
            "tensor([-14.4939], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}